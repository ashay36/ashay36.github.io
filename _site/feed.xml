<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en_us"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en_us" /><updated>2021-09-29T20:36:18+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ashay Ajbani</title><author><name>Sal</name></author><entry><title type="html">Autonomously Navigating a Robot using RRT Path Planning algorithm in ROS</title><link href="http://localhost:4000/autonomous-robot-in-ros/" rel="alternate" type="text/html" title="Autonomously Navigating a Robot using RRT Path Planning algorithm in ROS" /><published>2021-05-12T00:00:00+05:30</published><updated>2021-05-12T00:00:00+05:30</updated><id>http://localhost:4000/autonomous-robot-in-ros</id><content type="html" xml:base="http://localhost:4000/autonomous-robot-in-ros/">&lt;p&gt;The project includes a robot being spawned in a restaurant world. The robot travels autonomously around the restaurant using the map developed and move_base package of ROS which uses the RRT algorithm for path plannning.&lt;/p&gt;

&lt;h3 id=&quot;to-run-the-code-in-your-machine-following-are-the-steps--&quot;&gt;To run the code in your machine, following are the steps :-&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Close the repository in your machine.&lt;/li&gt;
  &lt;li&gt;Copy the packages in your workspace.&lt;/li&gt;
  &lt;li&gt;Terminal 1 - catkin_make&lt;/li&gt;
  &lt;li&gt;Terminal 1 - source devel/setup.bash&lt;/li&gt;
  &lt;li&gt;Terminal 1 - roslaunch path_planning simulation.launch&lt;/li&gt;
  &lt;li&gt;Terminal 2 - roslaunch path_planning plan_path.launch&lt;/li&gt;
  &lt;li&gt;Give a goal location using “2D Nav Goal” option in RViz&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;restaurant-world&quot;&gt;Restaurant World&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/world.png&quot; alt=&quot;Restaurant&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rviz-window&quot;&gt;RViz window&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/rviz.png&quot; alt=&quot;RViz&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rviz-window-with-planned-path&quot;&gt;RViz window with planned path&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/path_planning.png&quot; alt=&quot;RViz with planned path&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;references--&quot;&gt;References :-&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;https://github.com/AtsushiSakai/PythonRobotics&lt;/li&gt;
  &lt;li&gt;https://www.theconstructsim.com/develop-the-robots-of-the-future/&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">The project includes a robot being spawned in a restaurant world. The robot travels autonomously around the restaurant using the map developed and move_base package of ROS which uses the RRT algorithm for path plannning.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/turtlebot3.jpg" /><media:content medium="image" url="http://localhost:4000/assets/images/turtlebot3.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">RRT (Rapidly Exploring Random Trees) Path Planning Algorithm</title><link href="http://localhost:4000/rrt/" rel="alternate" type="text/html" title="RRT (Rapidly Exploring Random Trees) Path Planning Algorithm" /><published>2021-01-21T00:00:00+05:30</published><updated>2021-01-21T00:00:00+05:30</updated><id>http://localhost:4000/rrt</id><content type="html" xml:base="http://localhost:4000/rrt/">&lt;p&gt;This repository contains implementation of RRT (Rapidly exploring Random Trees) path planning algorithm in Python and C++. The code has been documented for better readability and understanding.
The start, goal and obstacle co-ordinates can be changed from within the code itself.&lt;/p&gt;

&lt;h2 id=&quot;python&quot;&gt;Python&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;RRT Python&lt;/code&gt; folder contains the python file of the algorithm.&lt;/p&gt;

&lt;h4 id=&quot;dependencies&quot;&gt;Dependencies&lt;/h4&gt;
&lt;ul&gt;
    &lt;li&gt;
        &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;a href=&quot;https://matplotlib.org/&quot;&gt;Matplotlib&lt;/a&gt;
    &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;running-code-via-command-line&quot;&gt;Running code via command line&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Change directory to where the code file is&lt;/li&gt;
  &lt;li&gt;Execute command - &lt;code&gt;python rrt_python.py&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;c&quot;&gt;C++&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;RRT C++&lt;/code&gt; folder contains the C++ files of the algorithm. It also contains the Eigen and Matplotlibcpp library files required for the project&lt;/p&gt;

&lt;h4 id=&quot;dependencis&quot;&gt;Dependencis&lt;/h4&gt;
&lt;ul&gt;
    &lt;li&gt;
        &lt;a href=&quot;http://eigen.tuxfamily.org/index.php?title=Main_Page#License&quot;&gt;Eigen&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;a href=&quot;https://github.com/lava/matplotlib-cpp&quot;&gt;Matplotlib-cpp&lt;/a&gt;
    &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;running-code-via-termial-ubuntu&quot;&gt;Running code via Termial (Ubuntu)&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Change the directory to where the code files are&lt;/li&gt;
  &lt;li&gt;Execute command - &lt;code&gt;g++ main.cpp -I/path/to/Python.h/file -lpython-version&lt;/code&gt;. 
In my case, the command is - &lt;code&gt;g++ main.cpp -I/usr/include/python3.8 -lpython3.8&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;After successfully executing above command, execute command - &lt;code&gt;./a.out&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Checkout the RRT research paper &lt;a href=&quot;http://msl.cs.uiuc.edu/~lavalle/papers/LavKuf01.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">This repository contains implementation of RRT (Rapidly exploring Random Trees) path planning algorithm in Python and C++. The code has been documented for better readability and understanding. The start, goal and obstacle co-ordinates can be changed from within the code itself.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/rrt.png" /><media:content medium="image" url="http://localhost:4000/assets/images/rrt.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Wheat Detection</title><link href="http://localhost:4000/wheat-detection/" rel="alternate" type="text/html" title="Wheat Detection" /><published>2020-08-23T00:00:00+05:30</published><updated>2020-08-23T00:00:00+05:30</updated><id>http://localhost:4000/wheat-detection</id><content type="html" xml:base="http://localhost:4000/wheat-detection/">&lt;pre&gt;&lt;code&gt;Team Name : The Alphas

Authors : Ashay Ajbani and Pritam Rao

Competition Type : Object Detection

Solution Type : Transfer Learning

Number of Classes : 1

Pretrained Models Used : 
1) DETR (Submission 1)
2) Efficient Detector (Submission 2)

Public Leaderborad Rank : 481/2270

Private Leaderboard Rank : 354/2270
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The competition was hosted on &lt;code&gt;https://www.kaggle.com/c/global-wheat-detection&lt;/code&gt;.
The task was to detect wheat heads in images and draw a bounding box around it.&lt;/p&gt;

&lt;h3 id=&quot;our-approach&quot;&gt;Our Approach&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Submission 1&lt;/strong&gt; :&lt;/p&gt;

&lt;p&gt;For our first submission, we fine tuned pretrained &lt;em&gt;Efficient Detector&lt;/em&gt; model for our problem.
It gave us a score of 0.7331 on the public leaderboard.&lt;/p&gt;

&lt;p&gt;The file &lt;em&gt;wheat_detection_efficientdet.ipynb&lt;/em&gt; includes training as well as inference. We have used Test Time 
Augmentation and Weighted Boxes Fusion for making more accurate predictions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Submission 2&lt;/strong&gt; :&lt;/p&gt;

&lt;p&gt;For our second submission, we fine tuned pretrained &lt;em&gt;DETR&lt;/em&gt; model for our problem. It gave us a 
score of 0.5758 on the public leaderboard.&lt;/p&gt;

&lt;p&gt;We have uploaded the following DETR notebooks :&lt;/p&gt;

&lt;p&gt;1) &lt;em&gt;wheat_detection_detr_training.ipynb&lt;/em&gt; : Includes processing the dataset and training on detr.
 2) &lt;em&gt;wheat_detection_detr_inference.ipynb&lt;/em&gt; : Making predictions on the test images using the trained model.&lt;/p&gt;

&lt;p&gt;We have documented the notebook so that you can easily use for your own applications.&lt;/p&gt;

&lt;p&gt;You can checkout Pritam Rao’s github profile at &lt;code&gt;https://github.com/pritamrao746/&lt;/code&gt;&lt;/p&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">``` Team Name : The Alphas</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/wheat.jpg" /><media:content medium="image" url="http://localhost:4000/assets/images/wheat.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Emergency Vehicle Classification</title><link href="http://localhost:4000/vehicle-classification/" rel="alternate" type="text/html" title="Emergency Vehicle Classification" /><published>2020-08-08T00:00:00+05:30</published><updated>2020-08-08T00:00:00+05:30</updated><id>http://localhost:4000/vehicle-classification</id><content type="html" xml:base="http://localhost:4000/vehicle-classification/">&lt;pre&gt;&lt;code&gt;Team Name : The Alphas

Authors : Ashay Ajbani and Pritam Rao

Competition Type : Image Classification

Solution Type : Model Ensembling

Number of Classes : 2

Pretrained Models Used : VGG16 and NASnet Large

Private Leaderboard Rank : 36/10000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The competition was hosted on &lt;code&gt;https://www.analyticsvidhya.com/&lt;/code&gt;.
The task was to classify vehicles into emergency and non-emergency categories.&lt;/p&gt;

&lt;h3 id=&quot;our-approach&quot;&gt;Our Approach&lt;/h3&gt;
&lt;p&gt;We ensembled 5 models to make final predictions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Models&lt;/strong&gt; :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Model 1 : Fine Tuning VGG16 &lt;/li&gt;
&lt;li&gt; Model 2 : Fine Tuning VGG16 with l2 regularization &lt;/li&gt;
&lt;li&gt; Model 3 : k-fold validation &lt;/li&gt;
&lt;li&gt; Model 4 : Fine Tuning NASnet &lt;/li&gt;
&lt;li&gt; Model 5 : Fine Tuning NASnet with l2 regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The predictions taken by ensembling above 5 models
resulted in an accuracy greater than any of the individual models.&lt;/p&gt;

&lt;p&gt;Techniques used to reduce overfitting :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt; Data Augmentation &lt;/li&gt;
  &lt;li&gt; BatchNormalization &lt;/li&gt;
  &lt;li&gt; Dropout &lt;/li&gt;
  &lt;li&gt; l2 Regularization &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt; :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Model 1 : 0.9498 &lt;/li&gt;
&lt;li&gt; Model 2 : 0.9546 &lt;/li&gt;
&lt;li&gt; Model 3 : 0.9444 &lt;/li&gt;
&lt;li&gt; Model 4 : 0.9548 &lt;/li&gt;
&lt;li&gt; Model 5 : 0.9514 &lt;/li&gt;
&lt;li&gt; After Ensembling (final) : 0.9688 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can checkout Pritam Rao’s github profile at &lt;code&gt;https://github.com/pritamrao746/&lt;/code&gt;&lt;/p&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">``` Team Name : The Alphas</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/vehicle.jpg" /><media:content medium="image" url="http://localhost:4000/assets/images/vehicle.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Face Applications</title><link href="http://localhost:4000/face-applications/" rel="alternate" type="text/html" title="Face Applications" /><published>2020-06-17T00:00:00+05:30</published><updated>2020-06-17T00:00:00+05:30</updated><id>http://localhost:4000/face-applications</id><content type="html" xml:base="http://localhost:4000/face-applications/">&lt;p&gt;This repository contains all face related applications using opencv and deep learning libraries&lt;/p&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">This repository contains all face related applications using opencv and deep learning libraries</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/face_applications.jpg" /><media:content medium="image" url="http://localhost:4000/assets/images/face_applications.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">COVID-19 Face Mask Detection</title><link href="http://localhost:4000/face-mask-detection/" rel="alternate" type="text/html" title="COVID-19 Face Mask Detection" /><published>2020-05-21T00:00:00+05:30</published><updated>2020-05-21T00:00:00+05:30</updated><id>http://localhost:4000/face-mask-detection</id><content type="html" xml:base="http://localhost:4000/face-mask-detection/">&lt;h1 id=&quot;covid-19-face-mask-detection-&quot;&gt;COVID-19-Face-Mask-Detection-&lt;/h1&gt;
&lt;p&gt;A deep learning based model that detects whether a person has a face mask on or not with nearly 100% accuracy.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Author : Ashay Ajbani

Pretrained model used : MobileNetV2

Trainable parameters : 3M

Number of classes : 2

Train Accuracy : 99.29%

Validation Accuracy : 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;dependencies&quot;&gt;Dependencies&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt; &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;Tensorflow&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt; &lt;a href=&quot;https://www.keras.io/&quot;&gt;Keras&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt; &lt;a href=&quot;https://www.opencv.org/&quot;&gt;OpenCV&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt; &lt;a href=&quot;https://www.numpy.org/&quot;&gt;NumPy&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;For training refer &lt;i&gt;&lt;b&gt;mask_detection.ipynb&lt;/b&gt;&lt;/i&gt;&lt;/li&gt;
  &lt;li&gt;For testing on your own image run &lt;i&gt;&lt;b&gt;detect_facemask.py&lt;/b&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt; Techniques used to reduce overfitting &lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt; Data Augmentation &lt;/li&gt;
  &lt;li&gt; BatchNormalization &lt;/li&gt;
  &lt;li&gt; Dropout &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">COVID-19-Face-Mask-Detection- A deep learning based model that detects whether a person has a face mask on or not with nearly 100% accuracy.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/face_mask.jpg" /><media:content medium="image" url="http://localhost:4000/assets/images/face_mask.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Fruits Classifier</title><link href="http://localhost:4000/fruits-classifier/" rel="alternate" type="text/html" title="Fruits Classifier" /><published>2020-05-16T00:00:00+05:30</published><updated>2020-05-16T00:00:00+05:30</updated><id>http://localhost:4000/fruits-classifier</id><content type="html" xml:base="http://localhost:4000/fruits-classifier/">&lt;p&gt;A classifier that can classify up-to 120 different types of fruits and vegetables with 95% accuracy&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Author : Ashay Ajbani

Pretrained model used : VGG19

Trainable parameters : 8.37M

Number of classes : 120

Train accuracy: 97.39%

Validation accuracy : 95.64%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have used VGG19 model pre-trained on the Imagenet dataset and fine-tuned it.&lt;/p&gt;

&lt;p&gt;Many different combinations of hyperparameters were experimented of which this model
proved to be more promising. The notebook also includes the code to unzip the dataset.&lt;/p&gt;

&lt;p&gt;Techniques used to reduce overfitting :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt; Data Augmentation &lt;/li&gt;
  &lt;li&gt; BatchNormalization &lt;/li&gt;
  &lt;li&gt; Dropout &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To download the dataset, click on the following link:
https://www.kaggle.com/moltean/fruits&lt;/p&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">A classifier that can classify up-to 120 different types of fruits and vegetables with 95% accuracy</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/fruits.jpg" /><media:content medium="image" url="http://localhost:4000/assets/images/fruits.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">YOLO Object Detection</title><link href="http://localhost:4000/yolo-object-detection/" rel="alternate" type="text/html" title="YOLO Object Detection" /><published>2020-05-16T00:00:00+05:30</published><updated>2020-05-16T00:00:00+05:30</updated><id>http://localhost:4000/yolo-object-detection</id><content type="html" xml:base="http://localhost:4000/yolo-object-detection/">&lt;p&gt;The code implements Object Detection using YOLOv3. The code has been implemented using the OpenCV library.
It uses a YOLOv3 model pre-trained on the COCO dataset.&lt;/p&gt;

&lt;h3 id=&quot;dependencies&quot;&gt;Dependencies&lt;/h3&gt;

&lt;ul&gt;
    &lt;li&gt;
        &lt;a href=&quot;https://opencv.org/&quot;&gt;OpenCV&lt;/a&gt;
    &lt;/li&gt;
    &lt;li&gt;
        &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt;
    &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The weights can be downloaded from the following link :-&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://pjreddie.com/media/files/yolov3.weights
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;input&quot;&gt;Input&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/input.jpg&quot; alt=&quot;Dog&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;output&quot;&gt;Output&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/test.jpg&quot; alt=&quot;Output&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No. of objects detected - 3 &lt;br /&gt;&lt;/p&gt;</content><author><name>Ashay</name></author><category term="Jekyll" /><category term="tutorial" /><summary type="html">The code implements Object Detection using YOLOv3. The code has been implemented using the OpenCV library. It uses a YOLOv3 model pre-trained on the COCO dataset.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/yolo.png" /><media:content medium="image" url="http://localhost:4000/assets/images/yolo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>